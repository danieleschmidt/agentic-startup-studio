# Agentic Startup Studio ‚Äì **Production Edition v2.0**

> **Mission:** Systematically validate and process startup ideas through a secure, authenticated pipeline with AI-powered analysis, automated testing, and comprehensive observability to maximize fundable opportunity discovery.

---

## What's New in v2.0 (July 2025)

üîê **Secure API Gateway**: Centralized authentication with JWT tokens and rate limiting  
‚ö° **Performance Optimized**: <50ms vector search queries, <200ms API responses  
üìä **Full Observability**: OpenTelemetry tracing, Prometheus metrics, Grafana dashboards  
üí∞ **Budget Control**: Real-time cost monitoring with $62/cycle automated limits  
‚úÖ **90% Test Coverage**: Comprehensive testing with HIPAA compliance framework  
üöÄ **Production Ready**: Docker deployments, secret management, zero-downtime updates

## Why This Architecture?

1.  **Security-First Design**: All APIs protected by authentication, rate limiting, and comprehensive audit logging
2.  **Performance at Scale**: Sub-50ms vector similarity search with optimized HNSW indexing for 1M+ ideas
3.  **Cost-Controlled Operations**: Automated budget enforcement prevents overruns while maximizing value per cycle
4.  **Enterprise Observability**: Full distributed tracing and metrics for production monitoring and debugging

---

## Table of Contents

1.  [Key Features](#1-key-features)
2.  [SDLC & DevOps](#2-sdlc--devops)
3.  [Architecture](#3-pipeline-architecture)
4.  [Quick Start](#4-quick-start)
5.  [CLI Usage](#5-cli-usage)
6.  [Testing Framework](#6-testing-framework)
7.  [Configuration](#7-configuration)
8.  [Project Structure](#8-project-structure)
9.  [Development](#9-development)

---

## 1. Key Features

| Component | Technology | Purpose | Status |
|-----------|------------|---------|--------|
| **üîê API Gateway** | FastAPI + JWT + Rate Limiting | Secure authenticated access with comprehensive rate limiting | ‚úÖ v2.0 |
| **‚ö° Vector Search** | PostgreSQL + pgvector + HNSW | <50ms similarity queries with optimized indexing | ‚úÖ Optimized |
| **üìä Observability** | OpenTelemetry + Prometheus + Grafana | Full distributed tracing and monitoring | ‚úÖ Complete |
| **üí∞ Budget Control** | Real-time Monitoring + Alerts | Automated $62/cycle budget enforcement | ‚úÖ Active |
| **ü§ñ AI Pipeline** | Multi-Agent + LangGraph | Evidence collection, pitch generation, investor evaluation | ‚úÖ Enhanced |
| **üîç Data Validation** | Pydantic + Custom Framework | Multi-layered validation with duplicate detection | ‚úÖ Robust |
| **üèóÔ∏è Infrastructure** | Docker + Circuit Breakers + Health Checks | Production-ready deployment with fault tolerance | ‚úÖ Production |
| **üß™ Testing Suite** | pytest + 90% Coverage + HIPAA | Comprehensive testing with compliance validation | ‚úÖ Complete |

---

## 2. SDLC & DevOps

### üöÄ Production-Ready SDLC Implementation

This project implements a comprehensive **Software Development Life Cycle (SDLC)** with enterprise-grade DevOps practices:

| Component | Implementation | Status | Automation Level |
|-----------|---------------|--------|-----------------|
| **üìã Project Foundation** | Complete documentation, ADRs, project charter | ‚úÖ Complete | 95% |
| **‚öôÔ∏è Development Environment** | DevContainers, code quality tools, pre-commit hooks | ‚úÖ Complete | 90% |
| **üß™ Testing Infrastructure** | 90%+ coverage, unit/integration/e2e tests | ‚úÖ Complete | 85% |
| **üèóÔ∏è Build & Containerization** | Multi-stage Docker, semantic releases | ‚úÖ Complete | 92% |
| **üìä Monitoring & Observability** | Prometheus, Grafana, OpenTelemetry tracing | ‚úÖ Complete | 88% |
| **‚ö° CI/CD Workflows** | Automated testing, security scans, deployments | ‚úÖ Complete | 95% |
| **üìà Metrics & Automation** | Automated reporting, dependency updates | ‚úÖ Complete | 87% |
| **üîó Integration & Configuration** | Repository settings, branch protection | ‚úÖ Complete | 93% |

### Automation Features

#### üìä **Automated Metrics Collection**
- **Daily**: Code quality, security scans, dependency checks
- **Weekly**: Comprehensive reporting, repository maintenance
- **Real-time**: Performance monitoring, cost tracking

#### üîÑ **Continuous Integration**
- Automated testing on every PR
- Security vulnerability scanning
- Code quality gates with 90%+ coverage requirement
- Performance benchmarking

#### üõ°Ô∏è **Security & Compliance**
- Automated dependency updates (security patches)
- Secret scanning and vulnerability detection
- HIPAA compliance framework
- Comprehensive audit logging

#### üìã **Stakeholder Reporting**
- **Management Reports**: Executive summaries, KPIs, milestone tracking
- **Technical Reports**: Code quality, performance metrics, technical debt
- **Security Reports**: Vulnerability status, compliance metrics

### Quick SDLC Commands

```bash
# Run daily automation cycle
python scripts/automation/automation_orchestrator.py --task daily

# Generate comprehensive reports
python scripts/automation/automated_reporting.py --type all

# Repository health check
python scripts/automation/repository_maintenance.py --summary health-report.md

# Code quality analysis
python scripts/automation/code_quality_monitor.py --verbose
```

---

## 3. Pipeline Architecture

```mermaid
flowchart TD
    Input[Idea Input] --> Validate[Validation Engine]
    Validate --> Duplicate[Duplicate Detection]
    Duplicate --> Store[Storage Layer]
    Store --> Process[Pipeline Processing]
    Process --> Research[Evidence Collection]
    Research --> Deck[Pitch Deck Generation]
    Deck --> Test[Smoke Testing]
    Test --> Deploy[Deployment]

    subgraph Storage
        DB[(PostgreSQL)]
        Vector[(pgvector)]
    end

    subgraph Services
        Evidence[Evidence Collector]
        PitchGen[Pitch Generator]
        Budget[Budget Sentinel]
    end
```

### Pipeline Stages

| Stage | Status | Description | Outputs |
|-------|--------|-------------|---------|
| **IDEATE** | DRAFT | Initial idea conception and basic validation | Validated idea record |
| **RESEARCH** | RESEARCHING | Evidence collection and market research | Research data, citations |
| **DECK** | VALIDATING | Pitch deck generation and formatting | Pitch deck artifacts |
| **INVESTORS** | VALIDATED | Investor evaluation simulation | Funding scores |
| **MVP** | BUILDING | Minimum viable product development | MVP specifications |
| **SMOKE_TEST** | TESTING | Market validation testing | Performance metrics |
| **COMPLETE** | DEPLOYED | Full deployment and monitoring | Live product |

---

## 3. Quick Start

### Prerequisites

- Python 3.11+
- PostgreSQL 14+ with pgvector extension
- Git

### Installation

```bash
# Clone repository
git clone https://github.com/your-org/agentic-startup-studio.git
cd agentic-startup-studio

# Install dependencies using UV (recommended)
python uv-setup.py

# Or install with pip
pip install -r requirements.txt

# Set up environment variables (copy and edit)
cp .env.example .env

# Run tests to verify setup
pytest

# Seed an example idea (optional)
python scripts/seed_idea.py "HIPAA compliance checker SaaS"
```

#### UV Environment Setup

The project includes an enhanced UV setup script for fast, reliable environment management:

```bash
# Standard setup
python uv-setup.py

# Debug mode with detailed logging
python uv-setup.py --debug

# Or use environment variable
UV_SETUP_DEBUG=true python uv-setup.py
```

**Features:**
- **Comprehensive Logging**: Timestamped log files in `logs/` directory for troubleshooting
- **Performance Timing**: Detailed timing measurements for all setup operations
- **Cross-Platform**: Windows-compatible with proper UTF-8 encoding
- **Debug Mode**: Verbose logging via `--debug` flag or `UV_SETUP_DEBUG=true`
- **Error Handling**: Enhanced error context with recovery suggestions

### Basic Usage

```bash
# Create a new startup idea
python -m pipeline.cli.ingestion_cli create \
  --title "AI-Powered Code Review Assistant" \
  --description "Automated code review tool that provides intelligent feedback on pull requests" \
  --category "ai_ml"

# List all ideas
python -m pipeline.cli.ingestion_cli list

# Get idea details
python -m pipeline.cli.ingestion_cli get --id <idea-uuid>

# Advance idea through pipeline stages
python -m pipeline.cli.ingestion_cli advance --id <idea-uuid> --stage RESEARCH

# Run the pitch loop simulation
PYTHONPATH=. python scripts/run_pitch.py --tokens 1000 --threshold 0.8
```

---

## 4. CLI Usage

The CLI provides comprehensive idea management capabilities:

### Creating Ideas

```bash
# Interactive creation
python -m pipeline.cli.ingestion_cli create

# With all parameters
python -m pipeline.cli.ingestion_cli create \
  --title "Your Idea Title" \
  --description "Detailed description" \
  --category "saas" \
  --problem "Problem statement" \
  --solution "Solution description" \
  --market "Target market" \
  --evidence "https://evidence1.com,https://evidence2.com"
```

### Filtering and Search

```bash
# Filter by status
python -m pipeline.cli.ingestion_cli list --status VALIDATED

# Filter by category
python -m pipeline.cli.ingestion_cli list --category fintech

# Search in titles and descriptions
python -m pipeline.cli.ingestion_cli list --search "AI machine learning"

# Combine filters
python -m pipeline.cli.ingestion_cli list --status RESEARCHING --category ai_ml --limit 10
```

### Managing Ideas

```bash
# Update idea fields
python -m pipeline.cli.ingestion_cli update <idea-uuid> \
  --title "Updated Title" \
  --description "Updated description"

# Find similar ideas
python -m pipeline.cli.ingestion_cli similar <idea-uuid> --limit 5

# System health check
python -m pipeline.cli.ingestion_cli health

# Run standalone health checks
python scripts/run_health_checks.py --results-file health_check_results.json

# Serve API with health endpoints
# /health returns JSON status, /metrics exposes Prometheus metrics
# Set ENABLE_TRACING=true to emit OpenTelemetry spans
# External API calls automatically retry on failure using exponential backoff
# LLM token usage metrics are exported on http://localhost:9102/metrics
python scripts/serve_api.py --port 8000
```

---

## 5. Testing Framework

### Running Tests

```bash
# Run all tests
pytest

# Run with coverage
pytest --cov=pipeline --cov-report=html

# Run specific test categories
pytest tests/pipeline/models/        # Model tests
pytest tests/pipeline/ingestion/    # Ingestion tests
pytest tests/framework/             # Framework tests

# Run with verbose output
pytest -v
```

### Test Categories

| Category | Purpose | Coverage |
|----------|---------|----------|
| **Unit Tests** | Individual component testing | Models, validators, utilities |
| **Integration Tests** | Component interaction testing | Manager, repository, CLI |
| **Framework Tests** | Validation engine testing | Data flow, error handling |
| **E2E Tests** | Complete pipeline testing | Full workflow validation |

### Test Configuration

Tests use [`pytest.ini`](pytest.ini) for configuration and [`tests/conftest.py`](tests/conftest.py) for shared fixtures:

```python
# Available test fixtures
- test_db: In-memory database
- sample_idea: Valid idea instance
- idea_manager: Configured manager
- cli_runner: CLI test runner
```

---

## 6. Configuration

Configuration is managed through environment variables and Pydantic settings:

### Environment Variables

```bash
# Database Configuration
DB_HOST=localhost
DB_PORT=5432
DB_NAME=startup_studio
DB_USER=postgres
DB_PASSWORD=your_password

# Application Settings
ENVIRONMENT=development
LOG_LEVEL=INFO
SECRET_KEY=your-secret-key

# Secrets Management (New)
# If using Google Cloud Secret Manager, set GOOGLE_CLOUD_PROJECT and SECRET_IDS
# GOOGLE_CLOUD_PROJECT=your-gcp-project-id
# SECRET_IDS=secret-id-1,secret-id-2

# Validation Settings
SIMILARITY_THRESHOLD=0.8
MAX_IDEAS_PER_HOUR=10

# Budget Controls
TOTAL_CYCLE_BUDGET=62.00
OPENAI_BUDGET=10.00
GOOGLE_ADS_BUDGET=45.00
FUND_THRESHOLD=0.8
INVESTOR_PROFILE=vc
DECK_TEMPLATE_PATH=templates/deck_template.marp
SMOKE_TEST_RESULTS_DIR=smoke_tests
GENERATED_MVPS_DIR=generated_mvps
HEALTH_CHECK_RESULTS_FILE=health_check_results.json
# Infrastructure Settings
CIRCUIT_BREAKER_FAILURE_THRESHOLD=5
CIRCUIT_BREAKER_TIMEOUT_SECONDS=30
CIRCUIT_BREAKER_RECOVERY_TIMEOUT=60
CIRCUIT_BREAKER_SUCCESS_THRESHOLD=3
HEALTH_CHECK_INTERVAL=30
ENABLE_HEALTH_MONITORING=True
ENABLE_TRACING=False
QUALITY_GATE_ENABLED=True
QUALITY_GATE_TIMEOUT_SECONDS=30
```

### Configuration Categories

| Category | Purpose | Key Settings |
|----------|---------|--------------|
| **Database** | PostgreSQL connection and pgvector | Host, credentials, pool settings |
| **Validation** | Input validation and security | Length limits, filters, thresholds |
| **Embedding** | Text embedding configuration | Provider, model, caching |
| **Logging** | Application logging | Levels, formats, destinations |
| **Budget** | Cost control and monitoring | Limits, thresholds, alerts |

---

## 7. Project Structure

```
agentic-startup-studio/
‚îú‚îÄ‚îÄ pipeline/                    # Core pipeline implementation
‚îÇ   ‚îú‚îÄ‚îÄ cli/                    # Command-line interface
‚îÇ   ‚îú‚îÄ‚îÄ config/                 # Configuration management
‚îÇ   ‚îú‚îÄ‚îÄ ingestion/              # Data ingestion and validation
‚îÇ   ‚îú‚îÄ‚îÄ models/                 # Data models and schemas
‚îÇ   ‚îú‚îÄ‚îÄ services/               # Business logic services
‚îÇ   ‚îî‚îÄ‚îÄ storage/                # Data persistence layer
‚îú‚îÄ‚îÄ tests/                      # Comprehensive test suite
‚îÇ   ‚îú‚îÄ‚îÄ framework/              # Testing framework
‚îÇ   ‚îú‚îÄ‚îÄ pipeline/               # Pipeline component tests
‚îÇ   ‚îî‚îÄ‚îÄ integration/            # Integration tests
‚îú‚îÄ‚îÄ docs/                       # Documentation
‚îÇ   ‚îú‚îÄ‚îÄ specs/                  # Technical specifications
‚îÇ   ‚îî‚îÄ‚îÄ sample-data/            # Sample data and examples
‚îú‚îÄ‚îÄ tools/                      # External tool integrations
‚îú‚îÄ‚îÄ scripts/                    # Utility scripts
‚îî‚îÄ‚îÄ requirements.txt            # Python dependencies
```

---

## 8. Development

### Development Setup

```bash
# Install development dependencies
pip install -r requirements.txt
pip install -e .

# Set up pre-commit hooks
pre-commit install

# Run development server
python -m pipeline.main_pipeline --debug
```

### Contributing

1. Fork the repository
2. Create a feature branch: `git checkout -b feature/new-feature`
3. Make changes and add tests
4. Run tests: `pytest`
5. Submit a pull request

### Code Quality

- **Linting**: Uses `ruff` for code formatting and linting
- **Type Checking**: Uses `mypy` for static type analysis
- **Testing**: Minimum 80% test coverage required
- **Documentation**: All public APIs must be documented

For detailed development guidelines, see [`docs/contributing-guide.md`](docs/).

---

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.
