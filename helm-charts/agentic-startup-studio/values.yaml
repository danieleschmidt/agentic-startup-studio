# Default values for agentic-startup-studio
# This is a YAML-formatted file.

# Global configuration
global:
  # Environment (development, staging, production)
  environment: production
  
  # Image registry and pull policy
  imageRegistry: ""
  imageTag: "1.0.0"
  imagePullPolicy: IfNotPresent
  imagePullSecrets: []
  
  # Storage class for persistent volumes
  storageClass: "gp3"
  
  # Security context
  securityContext:
    runAsNonRoot: true
    runAsUser: 65534
    fsGroup: 65534

# Application configuration
app:
  name: agentic-startup-studio
  version: "1.0.0"
  
  # Replica configuration
  replicaCount: 3
  
  # Image configuration
  image:
    repository: terragon/agentic-startup-studio
    tag: ""  # Uses global.imageTag if not specified
    pullPolicy: ""  # Uses global.imagePullPolicy if not specified
  
  # Container ports
  ports:
    http: 8080
    metrics: 8090
  
  # Resource limits and requests
  resources:
    requests:
      memory: "512Mi"
      cpu: "250m"
    limits:
      memory: "2Gi"
      cpu: "1000m"
  
  # Environment variables
  env:
    # Application settings
    LOG_LEVEL: "INFO"
    API_HOST: "0.0.0.0"
    API_PORT: "8080"
    
    # AI/ML configuration
    MAX_CONCURRENT_AGENTS: "5"
    DEFAULT_MODEL: "gpt-4"
    TOKEN_BUDGET_LIMIT: "100000"
    
    # Feature flags
    ENABLE_TRACING: "true"
    ENABLE_METRICS: "true"
    ENABLE_HEALTH_CHECKS: "true"
    ENABLE_RATE_LIMITING: "true"
  
  # Secrets (these should be set in environment-specific values files)
  secrets:
    openai_api_key: ""
    anthropic_api_key: ""
    jwt_secret_key: ""
    encryption_key: ""
    github_token: ""
  
  # Health checks
  livenessProbe:
    httpGet:
      path: /health
      port: http
    initialDelaySeconds: 30
    periodSeconds: 10
    timeoutSeconds: 5
    failureThreshold: 3
  
  readinessProbe:
    httpGet:
      path: /ready
      port: http
    initialDelaySeconds: 5
    periodSeconds: 5
    timeoutSeconds: 3
    failureThreshold: 3
  
  startupProbe:
    httpGet:
      path: /health
      port: http
    initialDelaySeconds: 10
    periodSeconds: 5
    timeoutSeconds: 3
    failureThreshold: 30

# AI Agent Worker configuration
aiAgentWorker:
  enabled: true
  name: ai-agent-worker
  
  # Replica configuration
  replicaCount: 2
  
  # Image configuration (uses same image as main app)
  image:
    repository: terragon/agentic-startup-studio
    tag: ""  # Uses global.imageTag if not specified
    pullPolicy: ""  # Uses global.imagePullPolicy if not specified
  
  # Container configuration
  command: ["python", "-m", "agents.multi_agent_workflow"]
  args: ["--worker-mode", "--concurrency=3"]
  
  # Resource limits and requests
  resources:
    requests:
      memory: "1Gi"
      cpu: "500m"
    limits:
      memory: "4Gi"
      cpu: "2000m"
  
  # Environment variables specific to workers
  env:
    WORKER_MODE: "true"
    MAX_CONCURRENT_AGENTS: "3"

# Service configuration
service:
  type: ClusterIP
  port: 80
  targetPort: http
  
  # Additional service ports
  ports:
    - name: http
      port: 80
      targetPort: 8080
      protocol: TCP
    - name: metrics
      port: 8090
      targetPort: 8090
      protocol: TCP
  
  # Service annotations
  annotations: {}
  # Load balancer configuration for cloud providers
  # annotations:
  #   service.beta.kubernetes.io/aws-load-balancer-type: "nlb"

# Ingress configuration
ingress:
  enabled: true
  className: "nginx"
  
  # Ingress annotations
  annotations:
    nginx.ingress.kubernetes.io/ssl-redirect: "true"
    nginx.ingress.kubernetes.io/force-ssl-redirect: "true"
    nginx.ingress.kubernetes.io/rate-limit: "100"
    nginx.ingress.kubernetes.io/rate-limit-window: "1m"
    nginx.ingress.kubernetes.io/cors-allow-origin: "https://terragon.ai,https://*.terragon.ai"
    nginx.ingress.kubernetes.io/cors-allow-methods: "GET, POST, PUT, DELETE, OPTIONS"
    nginx.ingress.kubernetes.io/cors-allow-headers: "DNT,Keep-Alive,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type,Range,Authorization"
    cert-manager.io/cluster-issuer: "letsencrypt-prod"
  
  # Ingress hosts
  hosts:
    - host: api.terragon.ai
      paths:
        - path: /
          pathType: Prefix
          backend:
            service:
              name: agentic-startup-studio
              port:
                number: 80
  
  # TLS configuration
  tls:
    - hosts:
        - api.terragon.ai
      secretName: agentic-startup-studio-tls

# Horizontal Pod Autoscaler
autoscaling:
  enabled: true
  minReplicas: 3
  maxReplicas: 20
  
  # Resource-based scaling
  targetCPUUtilizationPercentage: 70
  targetMemoryUtilizationPercentage: 80
  
  # Custom metrics scaling
  customMetrics:
    - type: Pods
      pods:
        metric:
          name: ai_agent_queue_depth
        target:
          type: AverageValue
          averageValue: "10"
    - type: Pods
      pods:
        metric:
          name: ai_agent_processing_time_seconds
        target:
          type: AverageValue
          averageValue: "30"
  
  # Scaling behavior
  behavior:
    scaleDown:
      stabilizationWindowSeconds: 300
      policies:
        - type: Percent
          value: 10
          periodSeconds: 60
        - type: Pods
          value: 2
          periodSeconds: 60
      selectPolicy: Min
    scaleUp:
      stabilizationWindowSeconds: 60
      policies:
        - type: Percent
          value: 50
          periodSeconds: 60
        - type: Pods
          value: 4
          periodSeconds: 60
      selectPolicy: Max

# AI Agent Worker Autoscaling
aiAgentWorkerAutoscaling:
  enabled: true
  minReplicas: 2
  maxReplicas: 10
  targetCPUUtilizationPercentage: 75
  targetMemoryUtilizationPercentage: 85
  
  # AI-specific scaling behavior
  behavior:
    scaleDown:
      stabilizationWindowSeconds: 600  # 10 minutes for AI workloads
      policies:
        - type: Percent
          value: 25
          periodSeconds: 300
      selectPolicy: Min
    scaleUp:
      stabilizationWindowSeconds: 120
      policies:
        - type: Percent
          value: 100
          periodSeconds: 60
        - type: Pods
          value: 3
          periodSeconds: 60
      selectPolicy: Max

# Pod Disruption Budget
podDisruptionBudget:
  enabled: true
  apiMinAvailable: 2  # For API pods
  workerMinAvailable: 1  # For worker pods

# Security Context
securityContext:
  runAsNonRoot: true
  runAsUser: 65534
  fsGroup: 65534
  
podSecurityContext:
  allowPrivilegeEscalation: false
  readOnlyRootFilesystem: true
  capabilities:
    drop:
      - ALL

# Network Policy
networkPolicy:
  enabled: true
  policyTypes:
    - Ingress
    - Egress
  
  # Ingress rules
  ingress:
    - from:
        - namespaceSelector:
            matchLabels:
              name: ingress-nginx
      ports:
        - protocol: TCP
          port: 8080
    - from:
        - namespaceSelector:
            matchLabels:
              name: monitoring
      ports:
        - protocol: TCP
          port: 8090

# PostgreSQL configuration (using Bitnami chart)
postgresql:
  enabled: true
  auth:
    enablePostgresUser: true
    postgresPassword: ""  # Set in environment-specific values
    username: "startup_studio"
    password: ""  # Set in environment-specific values
    database: "startup_studio"
  
  architecture: standalone
  primary:
    extendedConfiguration: |
      shared_preload_libraries = 'pg_stat_statements,vector'
      max_connections = 200
      shared_buffers = 1GB
      effective_cache_size = 3GB
      maintenance_work_mem = 512MB
      checkpoint_completion_target = 0.9
      wal_buffers = 16MB
      default_statistics_target = 100
      random_page_cost = 1.1
      effective_io_concurrency = 200
      work_mem = 32MB
      min_wal_size = 1GB
      max_wal_size = 4GB
      max_worker_processes = 8
      max_parallel_workers_per_gather = 4
      max_parallel_workers = 8
      max_parallel_maintenance_workers = 4
    
    initdb:
      scripts:
        01-extensions.sql: |
          CREATE EXTENSION IF NOT EXISTS vector;
          CREATE EXTENSION IF NOT EXISTS pg_stat_statements;
          CREATE EXTENSION IF NOT EXISTS btree_gin;
          CREATE SCHEMA IF NOT EXISTS app;
          GRANT ALL ON SCHEMA app TO postgres;
          GRANT USAGE ON SCHEMA app TO PUBLIC;
    
    resources:
      requests:
        memory: "1Gi"
        cpu: "500m"
      limits:
        memory: "4Gi"
        cpu: "2000m"
    
    persistence:
      enabled: true
      storageClass: ""  # Uses global.storageClass
      size: 100Gi
  
  metrics:
    enabled: true
    image:
      registry: docker.io
      repository: prometheuscommunity/postgres-exporter
      tag: v0.12.1
    resources:
      requests:
        memory: "128Mi"
        cpu: "100m"
      limits:
        memory: "256Mi"
        cpu: "200m"

# Redis configuration (using Bitnami chart)
redis:
  enabled: true
  architecture: standalone
  
  auth:
    enabled: false  # Disabled for development, enable in production
    password: ""
  
  master:
    configuration: |
      maxmemory 1gb
      maxmemory-policy allkeys-lru
      save 900 1
      save 300 10
      save 60 10000
      stop-writes-on-bgsave-error yes
      rdbcompression yes
      rdbchecksum yes
      timeout 300
      tcp-keepalive 300
      loglevel notice
      appendonly yes
      appendfilename "appendonly.aof"
      appendfsync everysec
      no-appendfsync-on-rewrite no
      auto-aof-rewrite-percentage 100
      auto-aof-rewrite-min-size 64mb
    
    resources:
      requests:
        memory: "512Mi"
        cpu: "250m"
      limits:
        memory: "2Gi"
        cpu: "1000m"
    
    persistence:
      enabled: true
      storageClass: ""  # Uses global.storageClass
      size: 50Gi
  
  metrics:
    enabled: true
    image:
      registry: docker.io
      repository: oliver006/redis_exporter
      tag: v1.50.0
    resources:
      requests:
        memory: "64Mi"
        cpu: "50m"
      limits:
        memory: "128Mi"
        cpu: "100m"

# Monitoring configuration
monitoring:
  # Prometheus configuration
  prometheus:
    enabled: true
    server:
      persistentVolume:
        enabled: true
        size: 50Gi
        storageClass: ""  # Uses global.storageClass
      resources:
        requests:
          memory: "2Gi"
          cpu: "1000m"
        limits:
          memory: "4Gi"
          cpu: "2000m"
    
    # Alerting rules
    serverFiles:
      alerting_rules.yml:
        groups:
          - name: agentic-startup-studio
            rules:
              - alert: APIDown
                expr: up{job="agentic-startup-studio"} == 0
                for: 1m
                labels:
                  severity: critical
                annotations:
                  summary: "API is down"
              - alert: HighLatency
                expr: histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m])) > 2
                for: 2m
                labels:
                  severity: warning
                annotations:
                  summary: "High API latency"
  
  # Grafana configuration
  grafana:
    enabled: true
    adminPassword: ""  # Set in environment-specific values
    
    persistence:
      enabled: true
      size: 10Gi
      storageClass: ""  # Uses global.storageClass
    
    resources:
      requests:
        memory: "256Mi"
        cpu: "100m"
      limits:
        memory: "512Mi"
        cpu: "500m"
    
    # Pre-configured dashboards
    dashboardProviders:
      dashboardproviders.yaml:
        apiVersion: 1
        providers:
          - name: 'default'
            orgId: 1
            folder: ''
            type: file
            disableDeletion: false
            editable: true
            options:
              path: /var/lib/grafana/dashboards/default
    
    dashboards:
      default:
        ai-ml-operations:
          gnetId: 12345  # Custom dashboard ID
          revision: 1
          datasource: Prometheus
        business-metrics:
          gnetId: 12346  # Custom dashboard ID
          revision: 1
          datasource: Prometheus
  
  # Jaeger configuration
  jaeger:
    enabled: true
    storage:
      type: memory
    
    collector:
      resources:
        requests:
          memory: "256Mi"
          cpu: "100m"
        limits:
          memory: "512Mi"
          cpu: "500m"
    
    query:
      resources:
        requests:
          memory: "128Mi"
          cpu: "50m"
        limits:
          memory: "256Mi"
          cpu: "200m"

# Service Account
serviceAccount:
  create: true
  annotations: {}
  name: ""

# RBAC
rbac:
  create: true

# Node selection and tolerations
nodeSelector: {}
tolerations: []
affinity: {}

# Pod annotations
podAnnotations:
  prometheus.io/scrape: "true"
  prometheus.io/port: "8090"
  prometheus.io/path: "/metrics"

# Additional volumes and volume mounts
extraVolumes: []
extraVolumeMounts: []

# Init containers
initContainers: []

# Sidecar containers
sidecars: []